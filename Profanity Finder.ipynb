{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2g1c', '2 girls 1 cup', 'anal', 'ass', 'asshole', 'arsehole', 'assmunch', 'auto erotic', 'autoerotic', 'ballsack', 'bastard', 'bdsm', 'bestiality', 'bitch', 'bich', 'bimbo', 'bimbos', 'blowjob', 'blow job', 'blue waffle', 'boob', 'boobs', 'booty call', 'brown shower', 'brown showers', 'boner', 'bondage', 'bukake', 'bukkake', 'bullshit', 'bull shit', 'busty', 'clitoris', 'cock', 'cocks', 'cow girl', 'cow girls', 'cowgirl', 'cowgirls', 'crotch', 'cum', 'cumming', 'cuming', 'cunt', 'dick', 'dildo', 'deepthroat', 'deep throat', 'dog style', 'doggie style', 'doggiestyle', 'doggy style', 'doggystyle', 'dyke', 'erotic', 'erotism', 'fag', 'faggot', 'femdom', 'fingering', 'footjob', 'foot job', 'fuck', 'futanari', 'futanary', 'gangbang', 'gang bang', 'gokkun', 'golden shower', 'goldenshower', 'gay', 'handjob', 'hand job', 'hentai', 'hooker', 'horny', 'incest', 'jerkoff', 'jerk off', 'jizz', 'kinbaku', 'lesbian', 'masturbate', 'motherfucker', 'milf', 'muff', 'nigga', 'nigger', 'nigg', 'nipple', 'nipples', 'nude', 'nudes', 'orgy', 'panty', 'panties', 'penis', 'piss', 'playboy', 'porn', 'porno', 'pornography', 'pussy', 'rape', 'raping', 'rapist', 's&m', 's & m', 'sadism', 'scrotum', 'sex', 'semen', 'shemale', 'she male', 'shibari', 'shibary', 'shit', 'shota', 'slut', 'smegma', 'spunk', 'strip club', 'stripclub', 'suck', 'sucks', 'tit', 'tits', 'titties', 'titty', 'threesome', 'three some', 'throating', 'twat', 'vagina', 'wank', 'whore', 'xxx', 'xx', 'yaoi', 'yury', 'cb', 'ccb', 'cheebye', 'chaocheebye', 'knn', 'kanina', 'knnccb', 'lj', 'lanjiao', 'asgm', 'ai sio gan mai', 'kkj', 'ku ku jiao', 'knnb', 'kaninabu', 'nanjiao', 'nnb', 'ni na bu', 'neh neh', 'nn', 'pcc', 'smlj', 'similanjiao', 'sml', 'similan', 'appm', 'ai piak piak mai']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "profanity_list = []\n",
    "with open('/Users/limjohn/Documents/Forum/profanity_wordlist.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    profanitylist_of_list = reader\n",
    "    for profanity in profanitylist_of_list:\n",
    "        profanity_list.extend(profanity)\n",
    "\n",
    "print(profanity_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "edmw_csv = pd.read_csv('/Users/limjohn/Downloads/Forum/edmw_data_clean.csv')\n",
    "reddit_csv = pd.read_csv('/Users/limjohn/Downloads/Forum/reddit_data_clean.csv')\n",
    "\n",
    "profanity_dict = {}\n",
    "for profanity in profanity_list:\n",
    "    profanity_dict[profanity] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c3c8516926a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'edmw_profanity_dict.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medmw_profanity_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'edmw_count_list.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "import pickle\n",
    "count_list =[]\n",
    "reddit_count_list = None\n",
    "edmw_count_list = None\n",
    "platforms = [edmw_csv, reddit_csv]\n",
    "num = 0\n",
    "def get_name(count):\n",
    "    if count == 0:\n",
    "        name = 'edmw'\n",
    "        count += 1\n",
    "    elif count == 1:\n",
    "        name = 'reddit'\n",
    "    return name\n",
    "\n",
    "def get_profanity_stats(platform):\n",
    "    count_list = []\n",
    "    profanity_dict = {}\n",
    "    for profanity in profanity_list:\n",
    "        profanity_dict[profanity] = 0\n",
    "    for line in platform['Comment']:\n",
    "        table = str.maketrans('', '', '1234567890') #removes digits.\n",
    "        trans = str(line).translate(table)\n",
    "        trans = trans.lower()\n",
    "        words = word_tokenize(trans)\n",
    "        for profanity in profanity_list:\n",
    "            count = 0\n",
    "            if profanity in words:\n",
    "                count = words.count(profanity)\n",
    "                count_list.append(count)\n",
    "                profanity_dict[profanity] = profanity_dict[profanity] + count \n",
    "\n",
    "    return count_list, profanity_dict\n",
    "\n",
    "def compile(platforms):\n",
    "    num = 0\n",
    "    for platform in platforms:\n",
    "        num += 1\n",
    "        x,y = get_profanity_stats(platform)\n",
    "        if num == 1:\n",
    "            edmw_profanity_dict = y\n",
    "            edmw_count_list = x\n",
    "        else:\n",
    "            reddit_profanity_dict = y\n",
    "            reddit_count_list = x\n",
    "    return edmw_profanity_dict, edmw_count_list, reddit_profanity_dict, reddit_count_list\n",
    "\n",
    "edmw_profanity_dict, edmw_count_list, reddit_profanity_dict, reddit_count_list = compile(platforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('edmw_profanity_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(edmw_profanity_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('edmw_count_list.pickle', 'wb') as handle2:\n",
    "    pickle.dump(edmw_count_list, handle2, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('reddit_profanity_dict.pickle', 'wb') as handle3:\n",
    "    pickle.dump(reddit_profanity_dict, handle3, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('reddit_count_list.pickle', 'wb') as handle4:\n",
    "    pickle.dump(reddit_count_list, handle4, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('edmw_profanity_dict.pickle', 'rb') as h:\n",
    "    edmw_profanity_dict = pickle.load(h)\n",
    "    \n",
    "with open('edmw_count_list.pickle', 'rb') as a:\n",
    "    edmw_count_list = pickle.load(a)\n",
    "    \n",
    "with open('reddit_profanity_dict.pickle', 'rb') as n:\n",
    "    reddit_profanity_dict = pickle.load(n)\n",
    "\n",
    "with open('reddit_count_list.pickle', 'rb') as d:\n",
    "    reddit_count_list = pickle.load(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_no(count_list, platform):\n",
    "    total_prof = sum(count_list)\n",
    "    total_no_comments = len(platform['Comment'])\n",
    "    no_comments_prof = len(count_list)\n",
    "    avg = total_prof/total_no_comments\n",
    "    return avg, no_comments_prof\n",
    "    \n",
    "def most_common_prof(prof_dict):\n",
    "    max_prof = max(prof_dict.keys(), key = prof_dict.get)\n",
    "    v = prof_dict[max_prof]\n",
    "    return max_prof, v\n",
    "\n",
    "prof_dict2 = [edmw_profanity_dict, reddit_profanity_dict]\n",
    "count_list2 = [edmw_count_list, reddit_count_list]\n",
    "\n",
    "def get_final_dict(platforms):\n",
    "    final_dict = {}\n",
    "    count = 0\n",
    "    for prof_dict in prof_dict2:\n",
    "        name = get_name(count)\n",
    "        count += 1\n",
    "        c,v = most_common_prof(prof_dict)\n",
    "        final_dict[name] = {'most_common': c,\n",
    "                           \"number_of_times\": v}\n",
    "    count = 0\n",
    "    for count_list in count_list2:\n",
    "        name = get_name(count)\n",
    "        count += 1\n",
    "        if name == 'reddit':\n",
    "            avg, no_comments_prof = avg_no(count_list, reddit_csv)\n",
    "        elif name == 'edmw':\n",
    "            avg, no_comments_prof = avg_no(count_list, reddit_csv)\n",
    "        final_dict[name].update({\"average\": avg,\n",
    "                                'comments with profanity': no_comments_prof})\n",
    "\n",
    "    return final_dict\n",
    "\n",
    "#avg = avg_no(edmw_count_list, edmw)\n",
    "#c,v  = most_common_prof(reddit_profanity_dict)\n",
    "#avg, c, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edmw': {'most_common': 'knn',\n",
       "  'number_of_times': 12655,\n",
       "  'average': 0.06574878484772918,\n",
       "  'comments with profanity': 72324},\n",
       " 'reddit': {'most_common': 'shit',\n",
       "  'number_of_times': 19696,\n",
       "  'average': 0.05959011018444118,\n",
       "  'comments with profanity': 63286}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d= get_final_dict(platforms)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2g1c': 0,\n",
       " '2 girls 1 cup': 0,\n",
       " 'anal': 551,\n",
       " 'ass': 1797,\n",
       " 'asshole': 302,\n",
       " 'arsehole': 149,\n",
       " 'assmunch': 0,\n",
       " 'auto erotic': 0,\n",
       " 'autoerotic': 2,\n",
       " 'ballsack': 5,\n",
       " 'bastard': 9,\n",
       " 'bdsm': 119,\n",
       " 'bestiality': 29,\n",
       " 'bitch': 745,\n",
       " 'bich': 11,\n",
       " 'bimbo': 150,\n",
       " 'bimbos': 14,\n",
       " 'blowjob': 92,\n",
       " 'blow job': 0,\n",
       " 'blue waffle': 0,\n",
       " 'boob': 157,\n",
       " 'boobs': 1219,\n",
       " 'booty call': 0,\n",
       " 'brown shower': 0,\n",
       " 'brown showers': 0,\n",
       " 'boner': 35,\n",
       " 'bondage': 72,\n",
       " 'bukake': 4,\n",
       " 'bukkake': 28,\n",
       " 'bullshit': 19,\n",
       " 'bull shit': 0,\n",
       " 'busty': 129,\n",
       " 'clitoris': 23,\n",
       " 'cock': 2224,\n",
       " 'cocks': 107,\n",
       " 'cow girl': 0,\n",
       " 'cow girls': 0,\n",
       " 'cowgirl': 72,\n",
       " 'cowgirls': 0,\n",
       " 'crotch': 77,\n",
       " 'cum': 3417,\n",
       " 'cumming': 200,\n",
       " 'cuming': 45,\n",
       " 'cunt': 250,\n",
       " 'dick': 1191,\n",
       " 'dildo': 96,\n",
       " 'deepthroat': 7,\n",
       " 'deep throat': 0,\n",
       " 'dog style': 0,\n",
       " 'doggie style': 0,\n",
       " 'doggiestyle': 0,\n",
       " 'doggy style': 0,\n",
       " 'doggystyle': 3,\n",
       " 'dyke': 8,\n",
       " 'erotic': 42,\n",
       " 'erotism': 1,\n",
       " 'fag': 126,\n",
       " 'faggot': 454,\n",
       " 'femdom': 4,\n",
       " 'fingering': 93,\n",
       " 'footjob': 1,\n",
       " 'foot job': 0,\n",
       " 'fuck': 18,\n",
       " 'futanari': 2,\n",
       " 'futanary': 0,\n",
       " 'gangbang': 40,\n",
       " 'gang bang': 0,\n",
       " 'gokkun': 1,\n",
       " 'golden shower': 0,\n",
       " 'goldenshower': 0,\n",
       " 'gay': 3325,\n",
       " 'handjob': 35,\n",
       " 'hand job': 0,\n",
       " 'hentai': 277,\n",
       " 'hooker': 105,\n",
       " 'horny': 1286,\n",
       " 'incest': 158,\n",
       " 'jerkoff': 3,\n",
       " 'jerk off': 0,\n",
       " 'jizz': 52,\n",
       " 'kinbaku': 0,\n",
       " 'lesbian': 250,\n",
       " 'masturbate': 138,\n",
       " 'motherfucker': 0,\n",
       " 'milf': 741,\n",
       " 'muff': 2,\n",
       " 'nigga': 84,\n",
       " 'nigger': 74,\n",
       " 'nigg': 0,\n",
       " 'nipple': 173,\n",
       " 'nipples': 162,\n",
       " 'nude': 642,\n",
       " 'nudes': 152,\n",
       " 'orgy': 100,\n",
       " 'panty': 315,\n",
       " 'panties': 921,\n",
       " 'penis': 628,\n",
       " 'piss': 402,\n",
       " 'playboy': 116,\n",
       " 'porn': 1865,\n",
       " 'porno': 90,\n",
       " 'pornography': 111,\n",
       " 'pussy': 6,\n",
       " 'rape': 3797,\n",
       " 'raping': 213,\n",
       " 'rapist': 345,\n",
       " 's&m': 0,\n",
       " 's & m': 0,\n",
       " 'sadism': 8,\n",
       " 'scrotum': 17,\n",
       " 'sex': 8448,\n",
       " 'semen': 114,\n",
       " 'shemale': 35,\n",
       " 'she male': 0,\n",
       " 'shibari': 3,\n",
       " 'shibary': 0,\n",
       " 'shit': 42,\n",
       " 'shota': 7,\n",
       " 'slut': 1039,\n",
       " 'smegma': 4,\n",
       " 'spunk': 1,\n",
       " 'strip club': 0,\n",
       " 'stripclub': 0,\n",
       " 'suck': 3074,\n",
       " 'sucks': 1329,\n",
       " 'tit': 107,\n",
       " 'tits': 468,\n",
       " 'titties': 40,\n",
       " 'titty': 6,\n",
       " 'threesome': 110,\n",
       " 'three some': 0,\n",
       " 'throating': 0,\n",
       " 'twat': 40,\n",
       " 'vagina': 192,\n",
       " 'wank': 0,\n",
       " 'whore': 477,\n",
       " 'xxx': 718,\n",
       " 'xx': 523,\n",
       " 'yaoi': 15,\n",
       " 'yury': 0,\n",
       " 'cb': 5081,\n",
       " 'ccb': 928,\n",
       " 'cheebye': 0,\n",
       " 'chaocheebye': 0,\n",
       " 'knn': 12655,\n",
       " 'kanina': 86,\n",
       " 'knnccb': 44,\n",
       " 'lj': 1994,\n",
       " 'lanjiao': 704,\n",
       " 'asgm': 184,\n",
       " 'ai sio gan mai': 0,\n",
       " 'kkj': 5293,\n",
       " 'ku ku jiao': 0,\n",
       " 'knnb': 32,\n",
       " 'kaninabu': 1,\n",
       " 'nanjiao': 0,\n",
       " 'nnb': 93,\n",
       " 'ni na bu': 0,\n",
       " 'neh neh': 0,\n",
       " 'nn': 184,\n",
       " 'pcc': 1641,\n",
       " 'smlj': 1825,\n",
       " 'similanjiao': 5,\n",
       " 'sml': 13,\n",
       " 'similan': 14,\n",
       " 'appm': 5,\n",
       " 'ai piak piak mai': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edmw_profanity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2g1c': 0,\n",
       " '2 girls 1 cup': 0,\n",
       " 'anal': 407,\n",
       " 'ass': 3730,\n",
       " 'asshole': 1303,\n",
       " 'arsehole': 38,\n",
       " 'assmunch': 0,\n",
       " 'auto erotic': 0,\n",
       " 'autoerotic': 2,\n",
       " 'ballsack': 4,\n",
       " 'bastard': 204,\n",
       " 'bdsm': 53,\n",
       " 'bestiality': 85,\n",
       " 'bitch': 1499,\n",
       " 'bich': 3,\n",
       " 'bimbo': 30,\n",
       " 'bimbos': 9,\n",
       " 'blowjob': 63,\n",
       " 'blow job': 0,\n",
       " 'blue waffle': 0,\n",
       " 'boob': 69,\n",
       " 'boobs': 302,\n",
       " 'booty call': 0,\n",
       " 'brown shower': 0,\n",
       " 'brown showers': 0,\n",
       " 'boner': 91,\n",
       " 'bondage': 21,\n",
       " 'bukake': 3,\n",
       " 'bukkake': 9,\n",
       " 'bullshit': 2013,\n",
       " 'bull shit': 0,\n",
       " 'busty': 15,\n",
       " 'clitoris': 16,\n",
       " 'cock': 850,\n",
       " 'cocks': 76,\n",
       " 'cow girl': 0,\n",
       " 'cow girls': 0,\n",
       " 'cowgirl': 3,\n",
       " 'cowgirls': 1,\n",
       " 'crotch': 78,\n",
       " 'cum': 294,\n",
       " 'cumming': 21,\n",
       " 'cuming': 1,\n",
       " 'cunt': 403,\n",
       " 'dick': 1529,\n",
       " 'dildo': 74,\n",
       " 'deepthroat': 1,\n",
       " 'deep throat': 0,\n",
       " 'dog style': 0,\n",
       " 'doggie style': 0,\n",
       " 'doggiestyle': 0,\n",
       " 'doggy style': 0,\n",
       " 'doggystyle': 1,\n",
       " 'dyke': 2,\n",
       " 'erotic': 19,\n",
       " 'erotism': 0,\n",
       " 'fag': 19,\n",
       " 'faggot': 42,\n",
       " 'femdom': 2,\n",
       " 'fingering': 26,\n",
       " 'footjob': 0,\n",
       " 'foot job': 0,\n",
       " 'fuck': 11597,\n",
       " 'futanari': 1,\n",
       " 'futanary': 0,\n",
       " 'gangbang': 3,\n",
       " 'gang bang': 0,\n",
       " 'gokkun': 0,\n",
       " 'golden shower': 0,\n",
       " 'goldenshower': 0,\n",
       " 'gay': 4643,\n",
       " 'handjob': 33,\n",
       " 'hand job': 0,\n",
       " 'hentai': 121,\n",
       " 'hooker': 46,\n",
       " 'horny': 245,\n",
       " 'incest': 194,\n",
       " 'jerkoff': 1,\n",
       " 'jerk off': 0,\n",
       " 'jizz': 30,\n",
       " 'kinbaku': 0,\n",
       " 'lesbian': 366,\n",
       " 'masturbate': 122,\n",
       " 'motherfucker': 139,\n",
       " 'milf': 53,\n",
       " 'muff': 3,\n",
       " 'nigga': 71,\n",
       " 'nigger': 29,\n",
       " 'nigg': 0,\n",
       " 'nipple': 82,\n",
       " 'nipples': 68,\n",
       " 'nude': 147,\n",
       " 'nudes': 125,\n",
       " 'orgy': 46,\n",
       " 'panty': 29,\n",
       " 'panties': 155,\n",
       " 'penis': 478,\n",
       " 'piss': 605,\n",
       " 'playboy': 21,\n",
       " 'porn': 967,\n",
       " 'porno': 32,\n",
       " 'pornography': 90,\n",
       " 'pussy': 331,\n",
       " 'rape': 1304,\n",
       " 'raping': 120,\n",
       " 'rapist': 139,\n",
       " 's&m': 0,\n",
       " 's & m': 0,\n",
       " 'sadism': 6,\n",
       " 'scrotum': 14,\n",
       " 'sex': 5929,\n",
       " 'semen': 72,\n",
       " 'shemale': 2,\n",
       " 'she male': 0,\n",
       " 'shibari': 0,\n",
       " 'shibary': 0,\n",
       " 'shit': 19696,\n",
       " 'shota': 6,\n",
       " 'slut': 126,\n",
       " 'smegma': 5,\n",
       " 'spunk': 5,\n",
       " 'strip club': 0,\n",
       " 'stripclub': 1,\n",
       " 'suck': 2211,\n",
       " 'sucks': 3025,\n",
       " 'tit': 55,\n",
       " 'tits': 155,\n",
       " 'titties': 28,\n",
       " 'titty': 29,\n",
       " 'threesome': 56,\n",
       " 'three some': 0,\n",
       " 'throating': 1,\n",
       " 'twat': 65,\n",
       " 'vagina': 169,\n",
       " 'wank': 75,\n",
       " 'whore': 111,\n",
       " 'xxx': 324,\n",
       " 'xx': 362,\n",
       " 'yaoi': 33,\n",
       " 'yury': 0,\n",
       " 'cb': 746,\n",
       " 'ccb': 116,\n",
       " 'cheebye': 73,\n",
       " 'chaocheebye': 0,\n",
       " 'knn': 691,\n",
       " 'kanina': 33,\n",
       " 'knnccb': 53,\n",
       " 'lj': 51,\n",
       " 'lanjiao': 155,\n",
       " 'asgm': 8,\n",
       " 'ai sio gan mai': 0,\n",
       " 'kkj': 154,\n",
       " 'ku ku jiao': 0,\n",
       " 'knnb': 6,\n",
       " 'kaninabu': 2,\n",
       " 'nanjiao': 0,\n",
       " 'nnb': 4,\n",
       " 'ni na bu': 0,\n",
       " 'neh neh': 0,\n",
       " 'nn': 40,\n",
       " 'pcc': 134,\n",
       " 'smlj': 271,\n",
       " 'similanjiao': 10,\n",
       " 'sml': 5,\n",
       " 'similan': 11,\n",
       " 'appm': 1,\n",
       " 'ai piak piak mai': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_profanity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_sorted = sorted(edmw_profanity_dict.items() ,key = lambda x: x[1], reverse = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "edmw_sorted = sorted(reddit_profanity_dict.items() ,key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('edmw_sorted.pickle', 'wb') as b:\n",
    "    pickle.dump(edmw_sorted, b, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('reddit_sorted.pickle', 'wb') as p:\n",
    "    pickle.dump(reddit_sorted, p, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('edmw_sorted.pickle', 'rb') as a:\n",
    "    edmw_sorted = pickle.load(a)\n",
    "with open('reddit_sorted.pickle', 'rb') as z:\n",
    "    reddit_sorted = pickle.load(z)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
